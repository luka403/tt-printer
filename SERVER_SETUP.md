# üöÄ Setup Ollama API na Serveru

## üìã Plan
1. Instaliraj Ollama na serveru
2. Expose API preko reverse proxy (Nginx) ili direktno
3. A≈æuriraj Node.js kod da koristi remote API

---

## 1Ô∏è‚É£ INSTALACIJA OLLAMA NA SERVERU

### Linux Server:
```bash
# Instaliraj Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pokreni Ollama servis
ollama serve

# Ili kao systemd service (preporuƒçeno):
sudo systemctl enable ollama
sudo systemctl start ollama
```

### Proveri da radi:
```bash
curl http://localhost:11434/api/tags
```

---

## 2Ô∏è‚É£ EXPOSE API (2 OPCIJE)

### OPCIJA A: Direktno (brzo, ali manje sigurno)
```bash
# Ollama veƒá slu≈°a na localhost:11434
# Da bi bilo dostupno sa spolja≈°nje IP:

# 1. Promeni bind address u Ollama config
# Kreiraj/uredi: ~/.ollama/config
OLLAMA_HOST=0.0.0.0:11434

# 2. Restartuj servis
sudo systemctl restart ollama

# 3. Otvori firewall port (ako ima≈°)
sudo ufw allow 11434/tcp
```

**‚ö†Ô∏è Napomena:** Ovo nije sigurno bez autentifikacije! Koristi samo ako je server iza VPN-a ili firewall-a.

---

### OPCIJA B: Nginx Reverse Proxy (PREPORUƒåENO) ‚úÖ

#### 1. Instaliraj Nginx:
```bash
sudo apt update
sudo apt install nginx
```

#### 2. Kreiraj Nginx config:
```bash
sudo nano /etc/nginx/sites-available/ollama-api
```

**Sadr≈æaj:**
```nginx
server {
    listen 80;
    server_name tvoj-server-ip-ili-domen.com;  # Zameni sa svojim IP ili domenom

    # Rate limiting (opciono, ali preporuƒçeno)
    limit_req_zone $binary_remote_addr zone=llm_limit:10m rate=10r/s;

    location / {
        limit_req zone=llm_limit burst=20 nodelay;
        
        proxy_pass http://localhost:11434;
        proxy_http_version 1.1;
        
        # Headers za WebSocket (ako koristi≈° streaming)
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # Standardni headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts (LLM mo≈æe da traje dugo)
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
}
```

#### 3. Enable config i restart:
```bash
sudo ln -s /etc/nginx/sites-available/ollama-api /etc/nginx/sites-enabled/
sudo nginx -t  # Test config
sudo systemctl reload nginx
```

#### 4. Otvori port 80:
```bash
sudo ufw allow 80/tcp
```

---

## 3Ô∏è‚É£ SSL/HTTPS (OPCIONO, ali preporuƒçeno)

Ako ima≈° domen, koristi Let's Encrypt:

```bash
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d tvoj-domen.com
```

---

## 4Ô∏è‚É£ TESTIRANJE API-ja

### Sa servera:
```bash
curl http://localhost:11434/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.1:8b",
    "messages": [
      {"role": "user", "content": "Hello"}
    ]
  }'
```

### Sa spolja≈°nje ma≈°ine:
```bash
curl http://TVOJ-SERVER-IP/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.1:8b",
    "messages": [
      {"role": "user", "content": "Hello"}
    ]
  }'
```

---

## 5Ô∏è‚É£ A≈ΩURIRANJE NODE.JS KODA

Kada ti ka≈æe≈° da je API spreman, a≈æuriraƒáemo:

1. **`.env` fajl:**
```env
LLM_API_URL=http://TVOJ-SERVER-IP/v1
# ili sa HTTPS:
# LLM_API_URL=https://tvoj-domen.com/v1
LLM_MODEL=llama3.1:8b
LLM_API_KEY=ollama  # Ollama ne zahteva API key, ali mo≈æemo dodati ako ≈æeli≈°
```

2. **Kod veƒá radi!** Samo promeni URL u `.env`.

---

## üîí SIGURNOST (VA≈ΩNO!)

### 1. Dodaj Basic Auth (preko Nginx):
```bash
sudo apt install apache2-utils
sudo htpasswd -c /etc/nginx/.htpasswd username
# Unesi password

# Dodaj u nginx config:
auth_basic "Ollama API";
auth_basic_user_file /etc/nginx/.htpasswd;
```

### 2. Ili IP Whitelist:
```nginx
allow TVOJ-IP;
deny all;
```

### 3. Ili API Key middleware (naprednije):
- Mo≈æe≈° napraviti mali Node.js middleware koji proverava API key
- Ili koristi Nginx auth_request modul

---

## üìù CHECKLIST

- [ ] Ollama instaliran i radi
- [ ] Model instaliran (`ollama pull llama3.1:8b`)
- [ ] Nginx config kreiran
- [ ] Port 80 otvoren
- [ ] Test API poziv radi
- [ ] (Opciono) SSL/HTTPS pode≈°en
- [ ] (Opciono) Basic Auth ili IP whitelist

---

## üß™ KADA ZAVR≈†I≈†, JAVI MI:

1. **URL tvog API-ja:** `http://IP/v1` ili `https://domen.com/v1`
2. **Da li ima≈° autentifikaciju?** (API key, Basic Auth, itd.)
3. **Koji model koristi≈°?** (npr. `llama3.1:8b`)

I ja ƒáu ti:
- A≈æurirati `.env` fajl
- Dodati autentifikaciju u kod (ako treba)
- Testirati konekciju

---

## üÜò TROUBLESHOOTING

**Ollama ne radi:**
```bash
sudo systemctl status ollama
sudo journalctl -u ollama -f
```

**Nginx ne radi:**
```bash
sudo nginx -t
sudo systemctl status nginx
sudo tail -f /var/log/nginx/error.log
```

**Port blokiran:**
```bash
sudo ufw status
sudo netstat -tulpn | grep 11434
```










