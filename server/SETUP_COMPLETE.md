# âœ… Python LLM API - Setup Kompletiran!

## ğŸ“¦ Å ta je kreirano:

1. **`server/llm_api.py`** - FastAPI server sa Ollama integracijom
2. **`server/requirements.txt`** - Python dependencies
3. **`server/env.example`** - Environment template
4. **`server/start.sh`** - Quick start script
5. **`server/README.md`** - Detaljna dokumentacija
6. **`server/QUICK_START.md`** - Brzi vodiÄ

## ğŸ”‘ API Key Setup:

**Default API Key:** `tt-printer-secret-key-2025`

**PROMENI OVO u `.env` fajlu pre produkcije!**

---

## ğŸš€ Kako da pokreneÅ¡:

### Na serveru:
```bash
cd server
pip install -r requirements.txt
cp env.example .env
# Uredi .env i promeni API_KEY
python llm_api.py
```

Server Ä‡e raditi na `http://0.0.0.0:8000`

---

## ğŸ“¡ Kada eksponujeÅ¡ na port, javi mi:

1. **URL:** `http://TVOJ-SERVER-IP:8000/v1`
2. **API Key:** (koji si postavio u `.env`)

I ja Ä‡u:
- âœ… AÅ¾urirati `.env` u Node.js projektu
- âœ… Testirati konekciju
- âœ… Pokrenuti ceo pipeline

---

## ğŸ§ª Testiranje:

```bash
# Health check
curl http://localhost:8000/health

# Chat completions
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "X-API-Key: tt-printer-secret-key-2025" \
  -d '{"model":"llama3.1:8b","messages":[{"role":"user","content":"Hello"}]}'
```

---

## âœ… Node.js kod je spreman!

Tvoj `core/llm.ts` veÄ‡ koristi:
- âœ… `X-API-Key` header
- âœ… Remote API URL iz `.env`
- âœ… Timeout i error handling

Samo promeni `.env` kada eksponujeÅ¡ API! ğŸ‰










